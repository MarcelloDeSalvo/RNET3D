{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muti-task Rodent TBI segmentation\n",
    "## Skull-stripping and ROI Segmentation\n",
    "Author: Marcello De Salvo <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents<font><a class='anchor' id='top'></a>\n",
    "1. [Importing Libraries](#lib)\n",
    "2. [Problem Definition](#problem)\n",
    "3. [Data Description](#data)\n",
    "4. [Configuration](#conf)\n",
    "5. [Data Visualization](#visual)\n",
    "6. [Evaluation metrics](#metrics)  \n",
    "7. [Data Loader](#load)\n",
    "8. [Model](#model)\n",
    "9. [Results](#results)\n",
    "10. [Evaluation](#eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries <a class='anchor' id='lib'></a> [↑](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T17:08:48.305209Z",
     "iopub.status.busy": "2023-11-14T17:08:48.304408Z",
     "iopub.status.idle": "2023-11-14T17:09:33.289991Z",
     "shell.execute_reply": "2023-11-14T17:09:33.288050Z",
     "shell.execute_reply.started": "2023-11-14T17:08:48.305165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# neural imaging\n",
    "import nilearn as nl\n",
    "import nibabel as nib\n",
    "import nilearn.plotting as nlplt\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problem definiton<a class='anchor' id='problem'></a> [↑](#top)\n",
    "Problem: Skull-stripping and ROI semantic segmentation<br>\n",
    "Each pixel in the image has to be assigned one of the following labels: <br>\n",
    "- Background (label 0)\n",
    "- Lesion (red, label 1)\n",
    "- Ventricle contra (blue, label 3)\n",
    "- Ventricle ipsi (light green, label 13)\n",
    "- Third Ventricle (purple, label 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Image data descriptions <a class='anchor' id='data'></a> [↑](#top)\n",
    "\n",
    "All multimodal scans are available as  NIfTI files (.nii.gz), a commonly used medical imaging format to store brain imagin data obtained using MRI and describe different MRI settings \n",
    "1. **T1w (Flash)**\n",
    "2. **T2w (Rare)**\n",
    "\n",
    "Data were acquired directly in this institute.\n",
    "All the imaging datasets have been segmented manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Configuration <a class='anchor' id='conf'></a> [↑](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE PROCESSING\n",
    "import time\n",
    "\n",
    "config ={\n",
    "    'dataset_path': '..\\dataset_roi',\n",
    "    'input_shape': (80,80,80),\n",
    "    'target_resolution': (0.1,0.1,0.1),\n",
    "    'labels': [0,1,3,13,21], # 0: background, 1: lesion, 3: contra-ventricle, 13: ipsi-ventricle, 21: third ventricle\n",
    "    'mapping': {0:0, 1:1, 3:2, 13:2, 21:3}, # 0: background, 1: ventricles, 2: cortex, 3: hippocampus -> 4 classes\n",
    "    'num_classes': 4,\n",
    "    'in_channels': 1,\n",
    "    'batch_size': 8,\n",
    "    'epochs': 300,\n",
    "    'lr': 1e-3,\n",
    "    'model_name': \"mice_roi_unet\" + \"_ep\" + str(500) + time.strftime(\"_%d-%m-%Y_%H-%M\"),\n",
    "    'validation_split': 0.2,\n",
    "    'test_split': 0.1,\n",
    "    'mice_sampling_rate': 3,\n",
    "    'rats_sampling_rate': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Visualization <a class='anchor' id='visual'></a> [↑](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:09.905186Z",
     "iopub.status.busy": "2023-11-14T15:40:09.904889Z",
     "iopub.status.idle": "2023-11-14T15:40:10.989056Z",
     "shell.execute_reply": "2023-11-14T15:40:10.988053Z",
     "shell.execute_reply.started": "2023-11-14T15:40:09.905162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.visualization import *\n",
    "from utils.loader import load_data\n",
    "\n",
    "# Modalities\n",
    "modalities = ['N4', 'brain_mask', 'Labels']\n",
    "\n",
    "# Patient\n",
    "scan_type = 't2w-C52-RARE'\n",
    "scan_id = 'TBI_fm_19_50'\n",
    "scan_folder = os.path.join(config['dataset_path'], scan_type, scan_id, 'Anat')\n",
    "print(scan_folder)\n",
    "\n",
    "# Load data\n",
    "img, data, file_paths = load_data(scan_folder, scan_id, modalities)\n",
    "\n",
    "# Plot data\n",
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in the lesion mask\n",
    "print(f\"Unique values in the lesion mask: {np.unique(data['brain_mask'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:10.990656Z",
     "iopub.status.busy": "2023-11-14T15:40:10.990346Z",
     "iopub.status.idle": "2023-11-14T15:40:26.938081Z",
     "shell.execute_reply": "2023-11-14T15:40:26.937184Z",
     "shell.execute_reply.started": "2023-11-14T15:40:10.990628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "niimg = nl.image.load_img(file_paths['N4'])\n",
    "nimask = nl.image.load_img(file_paths['Labels'])\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(30, 40))\n",
    "\n",
    "# Plot data\n",
    "nlplt.plot_img(niimg, title='N4', axes=axes[0])\n",
    "nlplt.plot_roi(nimask, title='Labels', bg_img=niimg, axes=axes[1], cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print matrix shape\n",
    "print(f\"Matrix shape: {data['N4'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation metrics <a class='anchor' id='loss'></a> [↑](#metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:26.984199Z",
     "iopub.status.busy": "2023-11-14T15:40:26.983919Z",
     "iopub.status.idle": "2023-11-14T15:40:26.998326Z",
     "shell.execute_reply": "2023-11-14T15:40:26.997449Z",
     "shell.execute_reply.started": "2023-11-14T15:40:26.984176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from evaluation.metrics import *\n",
    "from evaluation.losses import *\n",
    "\n",
    "metrics = [accuracy_coefficient(), precision_coefficient(), sensitivity_coefficient(), specificity_coefficient(), dice_coefficient(), iou_coefficient(), volume_similarity_coefficient()]\n",
    "\n",
    "# append to metric a class_dice_coef for each class\n",
    "for i in range(config['num_classes']):\n",
    "    metrics.append(dice_coefficient(class_index=i, exclude_background=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Loader <a class='anchor' id='load'></a> [↑](#top)\n",
    "Loading all data into memory is not a good idea since the data are too big to fit in.<br>\n",
    "So we will create a DataGenerators class to load data on the fly as explained [here](https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loader import *\n",
    "\n",
    "# Main Dataset\n",
    "rodent_dataset = RodentDatasets(labels=config['labels'])\n",
    "\n",
    "# Add all datasets\n",
    "rodent_dataset.add_dataset(config['dataset_path'], 'T1w-C52-FLASH', sub_folder='Anat')\n",
    "rodent_dataset.add_dataset(config['dataset_path'], 'T1w-CD1-FLASH', sub_folder='Anat')\n",
    "rodent_dataset.add_dataset(config['dataset_path'], 'T2w-C52-RARE', sub_folder='Anat')\n",
    "rodent_dataset.add_dataset(config['dataset_path'], 'T2w-Caen\\\\3 weeks', sub_folder='')\n",
    "\n",
    "# Split data\n",
    "train_and_test_ids = rodent_dataset.get_subjects_list()\n",
    "print('Size of the dataset: ', len(train_and_test_ids))\n",
    "\n",
    "# Splitting\n",
    "train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=config['validation_split']) \n",
    "train_ids, test_ids = train_test_split(train_test_ids,test_size=config['test_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:26.999605Z",
     "iopub.status.busy": "2023-11-14T15:40:26.999318Z",
     "iopub.status.idle": "2023-11-14T15:40:27.011387Z",
     "shell.execute_reply": "2023-11-14T15:40:27.010541Z",
     "shell.execute_reply.started": "2023-11-14T15:40:26.999582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading manually the rats of different time points\n",
    "rats_dataset = RodentDatasets(labels=config['labels'])\n",
    "rats_dataset.add_dataset(config['dataset_path'], 'T2w-RATS', sub_folder='Anat')\n",
    "\n",
    "# Extract ids   \n",
    "rats_ids = rats_dataset.get_subjects_list()\n",
    "\n",
    "# Extract unique subjects by checking the first 4 characters of the second element of the tuple (e.g. RAT1_5w -> RAT1)\n",
    "id_char_length = 4\n",
    "rats_unique_ids = list(set([x[1][:id_char_length] for x in rats_ids]))\n",
    "\n",
    "# Print\n",
    "print('---- ')\n",
    "print('Unique rats ids: ', rats_unique_ids)\n",
    "\n",
    "# Select one rat at random for validation and use the rest for training\n",
    "val_rat = np.random.choice(rats_unique_ids)\n",
    "train_rats = [x for x in rats_unique_ids if x != val_rat]\n",
    "\n",
    "# Extract thet time points of the selected rats\n",
    "val_rat_id = [x for x in rats_ids if x[1][:id_char_length] == val_rat]\n",
    "train_rat_ids = [x for x in rats_ids if x[1][:id_char_length] in train_rats]\n",
    "\n",
    "# Print\n",
    "print('---- ')\n",
    "print('Validation rat id: ', val_rat, ' - time points: ', val_rat_id)\n",
    "print('Training rat ids: ', train_rats, ' - time points: ', train_rat_ids)\n",
    "\n",
    "# Merge the tuples in rats ids belonging to the the selected rats with the train and validation ids\n",
    "train_ids = train_ids * config['mice_sampling_rate'] + train_rat_ids * config['rats_sampling_rate']\n",
    "val_ids = val_ids * config['mice_sampling_rate'] + val_rat_id * config['rats_sampling_rate']\n",
    "test_ids = test_ids * config['mice_sampling_rate']\n",
    "\n",
    "# Print\n",
    "print('---- ')\n",
    "print('Training ids: ', train_ids)\n",
    "print('Validation ids: ', val_ids)\n",
    "print('Test ids: ', test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:27.013143Z",
     "iopub.status.busy": "2023-11-14T15:40:27.012571Z",
     "iopub.status.idle": "2023-11-14T15:40:27.023869Z",
     "shell.execute_reply": "2023-11-14T15:40:27.023072Z",
     "shell.execute_reply.started": "2023-11-14T15:40:27.013117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from preprocessing.preprocessor import Preprocessor, Resample, Reorient, Normalize, CorrectX10, MapLabels, RandomCropping, RandomAffine, GaussianBlur, Noise, Flip, Padder\n",
    "\n",
    "# ref image for reorientation\n",
    "ref_img = nib.load(os.path.join('../example', 'RARE', 'TBI_fm_19_49', 'Anat', 'TBI_fm_19_49_N4.nii.gz'))\n",
    "\n",
    "augmented = Preprocessor([\n",
    "    MapLabels(config['labels'], mapping=config['mapping']),\n",
    "    CorrectX10(),\n",
    "    Reorient(ref_img),\n",
    "    RandomAffine(rotation_range=[-5,5], scale_range=[0.95,1.05], probability=0.3),\n",
    "    GaussianBlur([0,0.6], probability=0.3),\n",
    "    Noise([0,0.05], probability=0.3),\n",
    "    Resample(target_resolution=config['target_resolution'], interpolation=0),\n",
    "    Normalize(),\n",
    "    Padder(config['input_shape'], 'constant'),\n",
    "    RandomCropping(config['input_shape'], mode='center', std=None),\n",
    "    Flip(axis_list=[0], probability=0.5),\n",
    "])\n",
    "\n",
    "preprocessor =  Preprocessor([\n",
    "    MapLabels(config['labels'], mapping=config['mapping']),\n",
    "    CorrectX10(),\n",
    "    Reorient(ref_img),\n",
    "    Resample(target_resolution=config['target_resolution'], interpolation=0),\n",
    "    Normalize(),\n",
    "    Padder(config['input_shape'], 'constant'),\n",
    "    RandomCropping(config['input_shape'], mode='center', std=None),\n",
    "    Flip(axis_list=[0], probability=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:27.027135Z",
     "iopub.status.busy": "2023-11-14T15:40:27.026844Z",
     "iopub.status.idle": "2023-11-14T15:40:27.044151Z",
     "shell.execute_reply": "2023-11-14T15:40:27.043342Z",
     "shell.execute_reply.started": "2023-11-14T15:40:27.027112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from preprocessing.generator import MultiTaskGenerator\n",
    "\n",
    "# Datasets Initialization\n",
    "training_generator = MultiTaskGenerator(train_ids, rodent_dataset, batch_size=config['batch_size'], preprocessor=augmented, config=config)\n",
    "valid_generator = MultiTaskGenerator(val_ids, rodent_dataset, batch_size=config['batch_size'], preprocessor=preprocessor, config=config)\n",
    "test_generator = MultiTaskGenerator(test_ids, rodent_dataset, batch_size=config['batch_size'], preprocessor=preprocessor, config=config)\n",
    "\n",
    "print(\"Val IDs: \", val_ids)\n",
    "print(\"Train IDs: \", train_ids)\n",
    "print(\"Test IDs: \", test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:27.045574Z",
     "iopub.status.busy": "2023-11-14T15:40:27.045248Z",
     "iopub.status.idle": "2023-11-14T15:40:27.616062Z",
     "shell.execute_reply": "2023-11-14T15:40:27.615076Z",
     "shell.execute_reply.started": "2023-11-14T15:40:27.045543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X,[Y,M]= training_generator.__getitem__(index=1) # Fetching the first batch  (X, [Seg, Mask])\n",
    "\n",
    "print('Img shape: ', X.shape) # Should be equal to (BATCH_SIZE, IMG_SIZE, IMG_SIZE, NUM_SLICES, IN_CHANNELS) \n",
    "print('Labels shape: ', Y.shape) # Should be equal to (BATCH_SIZE, IMG_SIZE, IMG_SIZE, NUM_SLICES, NUM_CLASSES)\n",
    "print('Brain mask shape:', M.shape) # Should be equal to (BATCH_SIZE, IMG_SIZE, IMG_SIZE, NUM_SLICES, 1)\n",
    "\n",
    "# print max and min values in X\n",
    "print(\"Max value in X: \", np.max(X))\n",
    "print(\"Min value in X: \", np.min(X))\n",
    "\n",
    "# Check if Y is one-hot encoded and has 4 different channels with label 1\n",
    "print(\"Unique values in Y: \", np.unique(Y))\n",
    "\n",
    "# print max and min values in Y\n",
    "print(\"Max value in Y: \", np.max(Y))\n",
    "print(\"Min value in Y: \", np.min(Y))\n",
    "\n",
    "# Plot preview\n",
    "sample=7\n",
    "layer=config['input_shape'][2]//2\n",
    "\n",
    "yhat=Y[sample]\n",
    "yhat[yhat==-1]=0 # Convert all -1 to 0\n",
    "yhat = np.argmax(yhat, axis=-1)\n",
    "\n",
    "print(\"Unique values in Y: \", np.unique(yhat))\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(np.rot90(X[sample,:,:,layer,0], k=-1),cmap='gray')\n",
    "plt.imshow(np.rot90(yhat[:,:,layer], k=-1), cmap='jet', alpha=0.6)\n",
    "plt.imshow(np.rot90(M[sample,:,:,layer,0], k=-1), cmap='gray', alpha=0.2)\n",
    "plt.title(\"Processed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_3D_array_comparison(np.rot90(X[sample,:,:,:,0],k=-1),np.rot90(Y[sample,:,:,:,0],k=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Data Split Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:29.646503Z",
     "iopub.status.busy": "2023-11-14T15:40:29.646190Z",
     "iopub.status.idle": "2023-11-14T15:40:29.835908Z",
     "shell.execute_reply": "2023-11-14T15:40:29.834929Z",
     "shell.execute_reply.started": "2023-11-14T15:40:29.646477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.bar([\"Train\",\"Validation\", \"Test\"],\n",
    "[len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red','blue'])\n",
    "\n",
    "plt.ylabel('Number of images')\n",
    "plt.title('Data distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model | 3D U-Net <a class='anchor' id='model'></a> [↑](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.networks import *\n",
    "\n",
    "# Example usage:\n",
    "filters = [16, 32, 64, 128, 256]\n",
    "model = mt_r_net_3d((None,None,None), config['in_channels'], config['num_classes'], filters, attention=True, residual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a pre-trained model for fine-tuning\n",
    "'''\n",
    "model = load_model('../results/mice_rnet_pretrained/mice_rnet_pretrained.h5', \n",
    "                    custom_objects={'mt_r_net_3d': mt_r_net_3d, \n",
    "                                    'diceCELoss': diceCELoss, 'diceBCELoss': diceBCELoss, 'loss':losses,\n",
    "                                    'mean_accuracy': accuracy_coefficient, 'mean_precision': precision_coefficient, 'mean_sensitivity': sensitivity_coefficient, \n",
    "                                    'mean_specificity': specificity_coefficient, 'mean_dice': dice_coefficient, 'mean_iou': iou_coefficient, \n",
    "                                    'mean_volume_similarity': volume_similarity_coefficient, 'class_0_dice': dice_coefficient(class_index=0, exclude_background=False),\n",
    "                                    'class_1_dice': dice_coefficient(class_index=1, exclude_background=False), 'class_2_dice': dice_coefficient(class_index=2, exclude_background=False),\n",
    "                                    'class_3_dice': dice_coefficient(class_index=3, exclude_background=False)})\n",
    "\n",
    "model.summary()\n",
    "    \n",
    "# compile the model\n",
    "model.compile(optimizer=Nadam(learning_rate=config['lr']), loss=losses, loss_weights=loss_weights, metrics=metrics)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:30.373367Z",
     "iopub.status.busy": "2023-11-14T15:40:30.372740Z",
     "iopub.status.idle": "2023-11-14T15:40:30.518812Z",
     "shell.execute_reply": "2023-11-14T15:40:30.517892Z",
     "shell.execute_reply.started": "2023-11-14T15:40:30.373332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print summary of the model giving the input shape to function\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "csv_logger = CSVLogger('../results/'+config['model_name']+'/training.log', separator=',', append=False)\n",
    "log_dir = \"../results/\"+config['model_name']+\"/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_path = \"../results/\"+config['model_name']+\"/checkpoint/\"\n",
    "\n",
    "callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-7, verbose=1),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True, mode='min'),\n",
    "        csv_logger\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2023-11-14T15:40:31.058559Z",
     "iopub.status.busy": "2023-11-14T15:40:31.058292Z",
     "iopub.status.idle": "2023-11-14T15:45:18.524754Z",
     "shell.execute_reply": "2023-11-14T15:45:18.523851Z",
     "shell.execute_reply.started": "2023-11-14T15:40:31.058534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "steps = len(train_ids) // config['batch_size']\n",
    "val_steps = len(val_ids) // config['batch_size']\n",
    "\n",
    "roi_loss = diceCELoss(smooth=1e-5, batch_wise=True, gamma=0.8)\n",
    "skullstrip_loss = diceBCELoss(alpha=0.6, smooth=1e-5, batch_wise=True)\n",
    "\n",
    "losses = {\n",
    "    'regions': roi_loss,\n",
    "    'brain_mask': skullstrip_loss,\n",
    "}\n",
    "loss_weights = {\n",
    "    'regions': 1,\n",
    "    'brain_mask': 1,\n",
    "}\n",
    "\n",
    "tasks_metrics = {\n",
    "    'regions': metrics,\n",
    "    'brain_mask': dice_coefficient(class_index=0, exclude_background=False),\n",
    "}\n",
    "\n",
    "model.compile(loss=losses, optimizer=tf.keras.optimizers.Nadam(learning_rate=1e-3), metrics=tasks_metrics, loss_weights=loss_weights)\n",
    "history = model.fit(training_generator,epochs=config['epochs'], steps_per_epoch=steps, callbacks= callbacks, validation_data=valid_generator, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"../results/\"+config['model_name']+\"/save_\" + config['model_name'] + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = pd.read_csv('../results/'+config['model_name']+'/training.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Results <a class='anchor' id='results'></a> [↑](#top)\n",
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:45:18.526538Z",
     "iopub.status.busy": "2023-11-14T15:45:18.526249Z",
     "iopub.status.idle": "2023-11-14T15:45:19.233641Z",
     "shell.execute_reply": "2023-11-14T15:45:19.232763Z",
     "shell.execute_reply.started": "2023-11-14T15:45:18.526511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import utils.visualization\n",
    "importlib.reload(utils.visualization)\n",
    "from utils.visualization import plot_history, plot_loss\n",
    "plot_loss(model_history, path='../results/'+config['model_name']+'/' + 'loss_history.png', log=False)\n",
    "plot_history(model_history, path='../results/'+config['model_name']+'/' + 'metrics_history.png', figsize=(50,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:45:36.855530Z",
     "iopub.status.busy": "2023-11-14T15:45:36.855184Z",
     "iopub.status.idle": "2023-11-14T15:45:44.453757Z",
     "shell.execute_reply": "2023-11-14T15:45:44.452813Z",
     "shell.execute_reply.started": "2023-11-14T15:45:36.855499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.visualization import plot_multitask\n",
    "# To plot the pre-processed data we can use our custom test generator with batch_size equal to 1\n",
    "test_plot_generator = MultiTaskGenerator(ids=test_ids, loader=rodent_dataset, batch_size=1, preprocessor=preprocessor, config=config, shuffle=True)\n",
    "for index in range(len(test_plot_generator))[:15]:\n",
    "    plot_multitask(val_ids, index, test_plot_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluation.inference import RandomCroppingPrediction\n",
    "from evaluation.postprocessing import ipsi_contra_division_callback\n",
    "\n",
    "# Take a random id from the validation set tuple\n",
    "id = test_ids[1]\n",
    "print(\"ID: \", id)\n",
    "\n",
    "# Preprocessor\n",
    "inferenceProcessor = Preprocessor([\n",
    "    CorrectX10(),\n",
    "    MapLabels(labels=config['labels']),\n",
    "    Resample(target_resolution=config['target_resolution'], interpolation=0),\n",
    "    Reorient(ref_img),\n",
    "    Normalize(),\n",
    "    Flip(axis_list=[0], probability=1),\n",
    "])\n",
    "\n",
    "# Get mouse object from loader\n",
    "mouse = rodent_dataset.get_subject(id)\n",
    "\n",
    "# Extract images and masks\n",
    "image, roi_ground_truth, brain_mask_ground_truth = mouse.get_images()\n",
    "\n",
    "# Preprocess and augment the images\n",
    "prep_image = inferenceProcessor.preprocess(image)\n",
    "\n",
    "# Predict regions and brain mask\n",
    "predictor = RandomCroppingPrediction(model, patch_size=config['input_shape'], stride=32, threshold=0.5, num_classes=config['num_classes'])\n",
    "results = predictor.random_cropping_inference(prep_image, with_brain_mask=True)\n",
    "Y_pred = results['roi']\n",
    "y_mask = results['brain_mask']\n",
    "\n",
    "# Post processing\n",
    "Y_pred = ipsi_contra_division_callback(visualize_pca=True, use_centroids=False)(Y_pred)\n",
    "\n",
    "# Explore the final roi mask\n",
    "explore_3D_overlay(arr_before=np.rot90(prep_image.get_fdata(), k=-1), mask=np.rot90(Y_pred, k=-1), axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Evaluation <a class='anchor' id='eval'></a> [↑](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:45:44.455454Z",
     "iopub.status.busy": "2023-11-14T15:45:44.455091Z",
     "iopub.status.idle": "2023-11-14T15:46:31.795683Z",
     "shell.execute_reply": "2023-11-14T15:46:31.794763Z",
     "shell.execute_reply.started": "2023-11-14T15:45:44.455418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T15:46:31.797145Z",
     "iopub.status.busy": "2023-11-14T15:46:31.796826Z",
     "iopub.status.idle": "2023-11-14T15:46:31.807470Z",
     "shell.execute_reply": "2023-11-14T15:46:31.806577Z",
     "shell.execute_reply.started": "2023-11-14T15:46:31.797118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from utils.utils import save_metrics, save_model_info\n",
    "\n",
    "# Print test\n",
    "print(test_ids)\n",
    "# Save metrics, model info, and augmentation info\n",
    "print(\"Model name: \", config['model_name'])\n",
    "save_metrics(results, model, path=f'../results/{config[\"model_name\"]}/metrics.txt')\n",
    "save_model_info(model, config, filters, test_ids, path=f'../results/{config[\"model_name\"]}/model_info.txt')\n",
    "augmented.save_configuration(path=f'../results/{config[\"model_name\"]}/augmentation_config.txt')\n",
    "preprocessor.save_configuration(path=f'../results/{config[\"model_name\"]}/preprocessor_config.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Full volume evaluation <a class='anchor' id='eval'></a> [↑](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.inference import FullVolumeEvaluation\n",
    "from evaluation.postprocessing import ipsi_contra_division_callback, morphology_refinement_callback\n",
    "\n",
    "inferenceProcessor = Preprocessor([\n",
    "    CorrectX10(),\n",
    "    MapLabels(labels=config['labels']),\n",
    "    Resample(target_resolution=config['target_resolution'], interpolation=0),\n",
    "    Reorient(ref_img),\n",
    "    Normalize(),\n",
    "])\n",
    "\n",
    "# ROIS\n",
    "full_volume_eval = FullVolumeEvaluation(model, test_ids, config, rodent_dataset, roi_postprocess_callback=ipsi_contra_division_callback(),\n",
    "                                        strides=[20,40], preprocessor=inferenceProcessor, path='../results/'+config['model_name']+'/', verbose=True)\n",
    "resu= full_volume_eval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BRAIN MASK\n",
    "full_volume_eval = FullVolumeEvaluation(model, test_ids, config, rodent_dataset, strides=[20,40], preprocessor=inferenceProcessor, \n",
    "                                        brain_mask_postprocess_callback=morphology_refinement_callback(), path='../results/'+config['model_name']+'/', verbose=True)\n",
    "resu= full_volume_eval.evaluate(evaluate_brain_mask=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
