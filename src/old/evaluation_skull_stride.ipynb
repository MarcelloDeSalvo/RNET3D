{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.vedo import plot_slicer_cloud, plot_volume_cloud, plot_two_volumes\n",
    "\n",
    "import utils.nifti\n",
    "importlib.reload(utils.nifti)\n",
    "from utils.nifti import estimate_volume\n",
    "\n",
    "# neural imaging\n",
    "import nibabel as nib\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from evaluation.evaluation import *\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "casi che quasi tutti non riescono a predirre bene\n",
    "- TBI_PTE_fm_20_08_3w_N4, c'è un vuoto nero che non prende come cervello\n",
    "- TBI_gv_20_42_N4 e TBI_gv_20_55_N4, uno è riflesso al contrario e l'altro è tutto deforme. Entrambi sono più scuri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vedo import Volume, show, settings\n",
    "import vedo\n",
    "vedo.settings.default_backend= 'vtkplotter'\n",
    "from vedo import *\n",
    "from vedo.applications import Slicer3DPlotter\n",
    "\n",
    "def plot_vol(nii_img, nii_mask, spacing=[1, 1, 1]):\n",
    "    '''\n",
    "    Plot a 3D image and a point cloud of the lesion mask in the same plot.\n",
    "    '''\n",
    "\n",
    "    plt = Plotter()\n",
    "\n",
    "    v2 = Volume(nii_img)\n",
    "\n",
    "    # Set voxel dimension in mm\n",
    "    v2.spacing(spacing)\n",
    "    v2.cmap('bone')\n",
    "\n",
    "    plt += v2\n",
    "\n",
    "    # Define class labels based on the mask values\n",
    "    class_labels = np.unique(nii_mask)\n",
    "    class_len = len(class_labels)\n",
    "    print('Class labels:', class_labels)\n",
    "    print('Number of classes:', class_len)\n",
    "    \n",
    "    # make a color map that goes from red to blue for each class\n",
    "    color_map = np.zeros((class_len, 3))\n",
    "    color_map[:, 0] = np.linspace(1, 0, class_len)\n",
    "    color_map[:, 2] = np.linspace(0, 1, class_len)\n",
    "    color_map[:, 1] = np.linspace(0, 0, class_len)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Create an empty dictionary to store point clouds\n",
    "    point_clouds = {}\n",
    "\n",
    "    i=0\n",
    "    for label in class_labels:\n",
    "        # Get voxel coordinates\n",
    "        voxel_coords = np.array(np.where(nii_mask == label)).T  * v2.spacing()\n",
    "        pts = Points(voxel_coords, r=3, c=color_map[i], alpha=0.5)\n",
    "        # Multiply by voxel dimension to get coordinates in mm\n",
    "\n",
    "        # Store the point cloud in the dictionary\n",
    "        point_clouds[label] = pts\n",
    "        i+=1\n",
    "\n",
    "\n",
    "    for label in class_labels:\n",
    "        plt += point_clouds[label]\n",
    "\n",
    "    plt.add_slider(\n",
    "        lambda w, e: [point_clouds[label].alpha(w.value) for label in class_labels],\n",
    "        xmin=0,\n",
    "        xmax=1,\n",
    "        value=0.5,\n",
    "        pos=\"bottom-right-vertical\",\n",
    "        title=\"Opacity\",\n",
    "    )\n",
    "\n",
    "    plt.add_slider(\n",
    "        lambda w, e: v2.alpha([0, w.value]),\n",
    "        xmin=0,\n",
    "        xmax=1,\n",
    "        value=0.1,\n",
    "        pos=\"bottom-left-vertical\",\n",
    "        title=\"Opacity\",\n",
    "    )\n",
    "\n",
    "    # set initial alpha of volume 2 to 0.1\n",
    "    v2.alpha([0, 0.01])\n",
    "\n",
    "    # Make the plot rotate automatically\n",
    "    plt += Text2D(\"Press q to exit\", pos=(0.8, 0.05), s=0.8)\n",
    "\n",
    "    return plt.show(viewup='z').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num patches:  [3 3 2]\n",
      "Class labels: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "Number of classes: 18\n"
     ]
    }
   ],
   "source": [
    "patch_size = (76,76,76)\n",
    "overlap = (8,8,8)\n",
    "\n",
    "\n",
    "# Call the preprocessing function, must be the same of preprocessing\n",
    "\n",
    "# declare random input volume of size 128x128x128\n",
    "input_volume = np.random.rand(150,150,111)\n",
    "input_volume = np.random.rand(150,150,111)\n",
    "# calculate the number of patches in each dimension\n",
    "num_patches = np.ceil((np.array(input_volume.shape) - np.array(patch_size)) / (np.array(patch_size) - np.array(overlap))+ 1).astype(int)\n",
    "print('Num patches: ', num_patches)\n",
    "\n",
    "predicted_patches = np.zeros_like(input_volume)\n",
    "\n",
    "count = 1\n",
    "# for each patch make a prediction\n",
    "for i in range(num_patches[0]):\n",
    "    for j in range(num_patches[1]):\n",
    "        for k in range(num_patches[2]):\n",
    "            start_i = i* (patch_size[0] - overlap[0])\n",
    "            start_j = j* (patch_size[1] - overlap[1])\n",
    "            start_k = k* (patch_size[2] - overlap[2])\n",
    "\n",
    "            # extract the current patch from the input volume\n",
    "            patch = input_volume[start_i:start_i + patch_size[0],\n",
    "                                    start_j:start_j + patch_size[1],\n",
    "                                    start_k:start_k + patch_size[2]]\n",
    "            \n",
    "            # perform inference on the patch\n",
    "            predicted_patch = count\n",
    "            predicted_patches[start_i:start_i + patch_size[0],\n",
    "                                start_j:start_j + patch_size[1],\n",
    "                                start_k:start_k + patch_size[2]] = predicted_patch\n",
    "            count += 1\n",
    "\n",
    "# cap the values to 1\n",
    "#predicted_patches[predicted_patches > 1] = 1\n",
    "\n",
    "# plot the input volume and the predicted volume\n",
    "plot_vol(input_volume, predicted_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  12.  14.  15.\n",
      "  16.  18.  20.  21.  24.  25.  27.  28.  30.  32.  35.  36.  40.  42.\n",
      "  45.  48.  49.  50.  54.  56.  60.  63.  64.  70.  72.  75.  80.  81.\n",
      "  84.  90.  96.  98. 100. 105. 108. 112. 120. 125. 126. 128. 135. 140.\n",
      " 144. 147. 150. 160. 162. 168. 175. 180. 189. 192. 196. 200. 210. 216.\n",
      " 224. 225. 240. 243. 245. 250. 252. 256. 270. 280. 288. 300. 315. 320.\n",
      " 324. 350. 360. 400. 405. 450. 500.]\n",
      "Number of classes: 91\n"
     ]
    }
   ],
   "source": [
    "def sliding_window_inference(data, patch_size, stride, threshold=0.5):\n",
    "    depth, height, width = data.shape\n",
    "    predictions = np.zeros((depth, height, width))\n",
    "    count_map = np.zeros((depth, height, width))\n",
    "\n",
    "    count = 1\n",
    "    # Calculate the number of steps required to cover each dimension\n",
    "    steps_d = max(1, (depth - patch_size[0]) // stride + 1)\n",
    "    steps_h = max(1, (height - patch_size[1]) // stride + 1)\n",
    "    steps_w = max(1, (width - patch_size[2]) // stride + 1)\n",
    "\n",
    "    for d in range(0, steps_d * stride, stride):\n",
    "        for h in range(0, steps_h * stride, stride):\n",
    "            for w in range(0, steps_w * stride, stride):\n",
    "                patch = data[d:min(d+patch_size[0], depth), h:min(h+patch_size[1], height), w:min(w+patch_size[2], width)]\n",
    "                prediction = count\n",
    "                predictions[d:min(d+patch_size[0], depth), h:min(h+patch_size[1], height), w:min(w+patch_size[2], width)] += 1\n",
    "                count_map[d:min(d+patch_size[0], depth), h:min(h+patch_size[1], height), w:min(w+patch_size[2], width)] += 1\n",
    "\n",
    "\n",
    "\n",
    "    # Avoid division by zero\n",
    "    # count_map[count_map == 0] = 1\n",
    "\n",
    "    # Average predictions\n",
    "    # predictions /= count_map\n",
    "\n",
    "    # Apply threshold for binary segmentation\n",
    "    # binary_predictions = (predictions >= threshold).astype(np.uint8)\n",
    "    plot_vol(data, predictions)\n",
    "sliding_window_inference(input_volume, patch_size=(76,76,76), stride=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
